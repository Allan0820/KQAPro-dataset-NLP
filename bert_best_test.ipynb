{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the test suite for the bert embeddings using the  all-MiniLM-L6-v2 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Cosine similarity of |  An Apple a day keeps the doctor away  | with |  Apple makes the best phones  | is  tensor(0.3631)\n",
      "Cosine similarity of |  An Apple a day keeps the doctor away  | with |  Apple servers are better than microsoft  | is  tensor(0.3049)\n",
      "Cosine similarity of |  An Apple a day keeps the doctor away  | with |  Apple is grown extensively in Kashmir in the winter season  | is  tensor(0.3269)\n",
      "Cosine similarity of |  Apple makes the best phones  | with |  An Apple a day keeps the doctor away  | is  tensor(0.3631)\n",
      "Cosine similarity of |  Apple makes the best phones  | with |  Apple servers are better than microsoft  | is  tensor(0.5272)\n",
      "Cosine similarity of |  Apple makes the best phones  | with |  Apple is grown extensively in Kashmir in the winter season  | is  tensor(0.2471)\n",
      "Cosine similarity of |  Apple servers are better than microsoft  | with |  An Apple a day keeps the doctor away  | is  tensor(0.3049)\n",
      "Cosine similarity of |  Apple servers are better than microsoft  | with |  Apple makes the best phones  | is  tensor(0.5272)\n",
      "Cosine similarity of |  Apple servers are better than microsoft  | with |  Apple is grown extensively in Kashmir in the winter season  | is  tensor(0.2110)\n",
      "Cosine similarity of |  Apple is grown extensively in Kashmir in the winter season  | with |  An Apple a day keeps the doctor away  | is  tensor(0.3269)\n",
      "Cosine similarity of |  Apple is grown extensively in Kashmir in the winter season  | with |  Apple makes the best phones  | is  tensor(0.2471)\n",
      "Cosine similarity of |  Apple is grown extensively in Kashmir in the winter season  | with |  Apple servers are better than microsoft  | is  tensor(0.2110)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines=['An Apple a day keeps the doctor away','Apple makes the best phones','Apple servers are better than microsoft','Apple is grown extensively in Kashmir in the winter season']\n",
    "\n",
    "model =SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_list_2=[]\n",
    "\n",
    "for line in lines:\n",
    "    embedding_list_2.append(model.encode(line))\n",
    "\n",
    "print(len(embedding_list_2[0]))\n",
    "\n",
    "for i in range (len((embedding_list_2))):\n",
    "    for j in range (len((embedding_list_2))):\n",
    "        if i==j:\n",
    "            continue \n",
    "        else:\n",
    "            cos = nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output = cos(torch.Tensor(embedding_list_2[i]),torch.Tensor(embedding_list_2[j]))\n",
    "            print(\"Cosine similarity of | \",lines[i],\" | with | \",lines[j],\" | is \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Cosine similarity of |  250 Kilometers  | with |  250000 Meters  | is  tensor(0.7417)\n",
      "Cosine similarity of |  250 Kilometers  | with |  14 Centimeters  | is  tensor(0.4366)\n",
      "Cosine similarity of |  250 Kilometers  | with |  456 Millimeters  | is  tensor(0.3959)\n",
      "Cosine similarity of |  250000 Meters  | with |  250 Kilometers  | is  tensor(0.7417)\n",
      "Cosine similarity of |  250000 Meters  | with |  14 Centimeters  | is  tensor(0.4833)\n",
      "Cosine similarity of |  250000 Meters  | with |  456 Millimeters  | is  tensor(0.5633)\n",
      "Cosine similarity of |  14 Centimeters  | with |  250 Kilometers  | is  tensor(0.4366)\n",
      "Cosine similarity of |  14 Centimeters  | with |  250000 Meters  | is  tensor(0.4833)\n",
      "Cosine similarity of |  14 Centimeters  | with |  456 Millimeters  | is  tensor(0.5829)\n",
      "Cosine similarity of |  456 Millimeters  | with |  250 Kilometers  | is  tensor(0.3959)\n",
      "Cosine similarity of |  456 Millimeters  | with |  250000 Meters  | is  tensor(0.5633)\n",
      "Cosine similarity of |  456 Millimeters  | with |  14 Centimeters  | is  tensor(0.5829)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines=['250 Kilometers','250000 Meters', '14 Centimeters', '456 Millimeters']\n",
    "\n",
    "model =SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_list_2=[]\n",
    "\n",
    "for line in lines:\n",
    "    embedding_list_2.append(model.encode(line))\n",
    "\n",
    "print(len(embedding_list_2[0]))\n",
    "\n",
    "for i in range (len((embedding_list_2))):\n",
    "    for j in range (len((embedding_list_2))):\n",
    "        if i==j:\n",
    "            continue \n",
    "        else:\n",
    "            cos = nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output = cos(torch.Tensor(embedding_list_2[i]),torch.Tensor(embedding_list_2[j]))\n",
    "            print(\"Cosine similarity of | \",lines[i],\" | with | \",lines[j],\" | is \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Cosine similarity of |  Kilometers  | with |  Meters  | is  tensor(0.6283)\n",
      "Cosine similarity of |  Kilometers  | with |  Centimeters  | is  tensor(0.5236)\n",
      "Cosine similarity of |  Kilometers  | with |  Millimeters  | is  tensor(0.5546)\n",
      "Cosine similarity of |  Kilometers  | with |  Countries  | is  tensor(0.3144)\n",
      "Cosine similarity of |  Kilometers  | with |  People  | is  tensor(0.1428)\n",
      "Cosine similarity of |  Meters  | with |  Kilometers  | is  tensor(0.6283)\n",
      "Cosine similarity of |  Meters  | with |  Centimeters  | is  tensor(0.6379)\n",
      "Cosine similarity of |  Meters  | with |  Millimeters  | is  tensor(0.6906)\n",
      "Cosine similarity of |  Meters  | with |  Countries  | is  tensor(0.2172)\n",
      "Cosine similarity of |  Meters  | with |  People  | is  tensor(0.1984)\n",
      "Cosine similarity of |  Centimeters  | with |  Kilometers  | is  tensor(0.5236)\n",
      "Cosine similarity of |  Centimeters  | with |  Meters  | is  tensor(0.6379)\n",
      "Cosine similarity of |  Centimeters  | with |  Millimeters  | is  tensor(0.7201)\n",
      "Cosine similarity of |  Centimeters  | with |  Countries  | is  tensor(0.1634)\n",
      "Cosine similarity of |  Centimeters  | with |  People  | is  tensor(0.1163)\n",
      "Cosine similarity of |  Millimeters  | with |  Kilometers  | is  tensor(0.5546)\n",
      "Cosine similarity of |  Millimeters  | with |  Meters  | is  tensor(0.6906)\n",
      "Cosine similarity of |  Millimeters  | with |  Centimeters  | is  tensor(0.7201)\n",
      "Cosine similarity of |  Millimeters  | with |  Countries  | is  tensor(0.1530)\n",
      "Cosine similarity of |  Millimeters  | with |  People  | is  tensor(0.1519)\n",
      "Cosine similarity of |  Countries  | with |  Kilometers  | is  tensor(0.3144)\n",
      "Cosine similarity of |  Countries  | with |  Meters  | is  tensor(0.2172)\n",
      "Cosine similarity of |  Countries  | with |  Centimeters  | is  tensor(0.1634)\n",
      "Cosine similarity of |  Countries  | with |  Millimeters  | is  tensor(0.1530)\n",
      "Cosine similarity of |  Countries  | with |  People  | is  tensor(0.3915)\n",
      "Cosine similarity of |  People  | with |  Kilometers  | is  tensor(0.1428)\n",
      "Cosine similarity of |  People  | with |  Meters  | is  tensor(0.1984)\n",
      "Cosine similarity of |  People  | with |  Centimeters  | is  tensor(0.1163)\n",
      "Cosine similarity of |  People  | with |  Millimeters  | is  tensor(0.1519)\n",
      "Cosine similarity of |  People  | with |  Countries  | is  tensor(0.3915)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines=['Kilometers','Meters', 'Centimeters', 'Millimeters','Countries','People']\n",
    "\n",
    "model =SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_list_2=[]\n",
    "\n",
    "for line in lines:\n",
    "    embedding_list_2.append(model.encode(line))\n",
    "\n",
    "print(len(embedding_list_2[0]))\n",
    "\n",
    "for i in range (len((embedding_list_2))):\n",
    "    for j in range (len((embedding_list_2))):\n",
    "        if i==j:\n",
    "            continue \n",
    "        else:\n",
    "            cos = nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output = cos(torch.Tensor(embedding_list_2[i]),torch.Tensor(embedding_list_2[j]))\n",
    "            print(\"Cosine similarity of | \",lines[i],\" | with | \",lines[j],\" | is \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Cosine similarity of |  Michael Jackson was an amazing artist  | with |  He pioneered pop music  | is  tensor(0.4378)\n",
      "Cosine similarity of |  Michael Jackson was an amazing artist  | with |  He is known as the king of pop  | is  tensor(0.2846)\n",
      "Cosine similarity of |  Michael Jackson was an amazing artist  | with |  Michael Jackson was a girl who lived happily ever after  | is  tensor(0.6009)\n",
      "Cosine similarity of |  He pioneered pop music  | with |  Michael Jackson was an amazing artist  | is  tensor(0.4378)\n",
      "Cosine similarity of |  He pioneered pop music  | with |  He is known as the king of pop  | is  tensor(0.6907)\n",
      "Cosine similarity of |  He pioneered pop music  | with |  Michael Jackson was a girl who lived happily ever after  | is  tensor(0.2071)\n",
      "Cosine similarity of |  He is known as the king of pop  | with |  Michael Jackson was an amazing artist  | is  tensor(0.2846)\n",
      "Cosine similarity of |  He is known as the king of pop  | with |  He pioneered pop music  | is  tensor(0.6907)\n",
      "Cosine similarity of |  He is known as the king of pop  | with |  Michael Jackson was a girl who lived happily ever after  | is  tensor(0.2179)\n",
      "Cosine similarity of |  Michael Jackson was a girl who lived happily ever after  | with |  Michael Jackson was an amazing artist  | is  tensor(0.6009)\n",
      "Cosine similarity of |  Michael Jackson was a girl who lived happily ever after  | with |  He pioneered pop music  | is  tensor(0.2071)\n",
      "Cosine similarity of |  Michael Jackson was a girl who lived happily ever after  | with |  He is known as the king of pop  | is  tensor(0.2179)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines=['Michael Jackson was an amazing artist','He pioneered pop music','He is known as the king of pop','Michael Jackson was a girl who lived happily ever after']\n",
    "\n",
    "model =SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_list_2=[]\n",
    "\n",
    "for line in lines:\n",
    "    embedding_list_2.append(model.encode(line))\n",
    "\n",
    "print(len(embedding_list_2[0]))\n",
    "\n",
    "for i in range (len((embedding_list_2))):\n",
    "    for j in range (len((embedding_list_2))):\n",
    "        if i==j:\n",
    "            continue \n",
    "        else:\n",
    "            cos = nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output = cos(torch.Tensor(embedding_list_2[i]),torch.Tensor(embedding_list_2[j]))\n",
    "            print(\"Cosine similarity of | \",lines[i],\" | with | \",lines[j],\" | is \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Cosine similarity of |  100  | with |  250  | is  tensor(0.6119)\n",
      "Cosine similarity of |  100  | with |  345.675  | is  tensor(0.2042)\n",
      "Cosine similarity of |  100  | with |  2342  | is  tensor(0.3256)\n",
      "Cosine similarity of |  250  | with |  100  | is  tensor(0.6119)\n",
      "Cosine similarity of |  250  | with |  345.675  | is  tensor(0.3848)\n",
      "Cosine similarity of |  250  | with |  2342  | is  tensor(0.4743)\n",
      "Cosine similarity of |  345.675  | with |  100  | is  tensor(0.2042)\n",
      "Cosine similarity of |  345.675  | with |  250  | is  tensor(0.3848)\n",
      "Cosine similarity of |  345.675  | with |  2342  | is  tensor(0.4177)\n",
      "Cosine similarity of |  2342  | with |  100  | is  tensor(0.3256)\n",
      "Cosine similarity of |  2342  | with |  250  | is  tensor(0.4743)\n",
      "Cosine similarity of |  2342  | with |  345.675  | is  tensor(0.4177)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines=['100','250','345.675','2342']\n",
    "\n",
    "model =SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_list_2=[]\n",
    "\n",
    "for line in lines:\n",
    "    embedding_list_2.append(model.encode(line))\n",
    "\n",
    "print(len(embedding_list_2[0]))\n",
    "\n",
    "for i in range (len((embedding_list_2))):\n",
    "    for j in range (len((embedding_list_2))):\n",
    "        if i==j:\n",
    "            continue \n",
    "        else:\n",
    "            cos = nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output = cos(torch.Tensor(embedding_list_2[i]),torch.Tensor(embedding_list_2[j]))\n",
    "            print(\"Cosine similarity of | \",lines[i],\" | with | \",lines[j],\" | is \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "Cosine similarity of |  100 Meters  | with |  250 Meters  | is  tensor(0.8326)\n",
      "Cosine similarity of |  100 Meters  | with |  3452 Meters  | is  tensor(0.7045)\n",
      "Cosine similarity of |  100 Meters  | with |  2342 Meters  | is  tensor(0.7137)\n",
      "Cosine similarity of |  250 Meters  | with |  100 Meters  | is  tensor(0.8326)\n",
      "Cosine similarity of |  250 Meters  | with |  3452 Meters  | is  tensor(0.8039)\n",
      "Cosine similarity of |  250 Meters  | with |  2342 Meters  | is  tensor(0.7601)\n",
      "Cosine similarity of |  3452 Meters  | with |  100 Meters  | is  tensor(0.7045)\n",
      "Cosine similarity of |  3452 Meters  | with |  250 Meters  | is  tensor(0.8039)\n",
      "Cosine similarity of |  3452 Meters  | with |  2342 Meters  | is  tensor(0.8344)\n",
      "Cosine similarity of |  2342 Meters  | with |  100 Meters  | is  tensor(0.7137)\n",
      "Cosine similarity of |  2342 Meters  | with |  250 Meters  | is  tensor(0.7601)\n",
      "Cosine similarity of |  2342 Meters  | with |  3452 Meters  | is  tensor(0.8344)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lines=['100 Meters','250 Meters','3452 Meters','2342 Meters']\n",
    "\n",
    "model =SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_list_2=[]\n",
    "\n",
    "for line in lines:\n",
    "    embedding_list_2.append(model.encode(line))\n",
    "\n",
    "print(len(embedding_list_2[0]))\n",
    "\n",
    "for i in range (len((embedding_list_2))):\n",
    "    for j in range (len((embedding_list_2))):\n",
    "        if i==j:\n",
    "            continue \n",
    "        else:\n",
    "            cos = nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output = cos(torch.Tensor(embedding_list_2[i]),torch.Tensor(embedding_list_2[j]))\n",
    "            print(\"Cosine similarity of | \",lines[i],\" | with | \",lines[j],\" | is \",output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
